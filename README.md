# RAG System for Question Answering

## Project Overview

This project is a Retrieval-Augmented Generation (RAG) system that allows users to ask questions and receive relevant answers based on the content of a pre-processed document. The document is automatically processed at startup, its text is split into chunks, and embeddings are generated and stored in ChromaDB. When a user asks a question, the system retrieves the most relevant chunk and uses Cohere's large language model (LLM) to generate a concise, one-sentence answer in the same language as the question.

## Features

- **Automated Document Processing**: A specific document (in DOCX format) is automatically loaded, processed, and prepared for querying when the system starts.
- **Text Chunking**: The document is split into smaller chunks for easier processing and embedding.
- **Embedding Generation**: Text chunks are transformed into embeddings using Cohere's API.
- **ChromaDB Storage**: The embeddings and corresponding text chunks are stored in ChromaDB for efficient retrieval.
- **Question Answering**: The user can ask a question, and the system will return a relevant answer based on the most pertinent chunk of the document, generated using Cohere's LLM.

## Requirements

- Python 3.9 or higher
- Dependencies (listed in `requirements.txt`)

## Installation

To run the project locally, follow these steps:

### 1. Clone the Repository:

   ```bash
   git clone https://github.com/GuilleGriffa/rag-service.git
   cd rag-service
```

### 2. Set up a virtual environment: 

It is recommended to use a virtual environment to manage dependencies. You can create and activate a virtual environment as follows:

```bash
   conda create -n name_env
   conda activate name_env
```

### 3. Install dependencies:

Install the required Python packages using `pip`:

```bash
   pip install -r requirements.txt
```

### 4. Set up environment variables:

Create a `.env` file in the root directory of the project, and add the following variables:

```env
COHERE_API_KEY=your_cohere_api_key
```
You can obtain a Cohere API key by signing up on the Cohere website.

## Usage 

### 1. Run the application: 

Once you have set up the environment, you can start the FastAPI application using `uvicorn`:

```bash
   uvicorn main:app --reload
```

### 2. API endpoints:

- `POST/ask`: This endpoint enables users to ask a question. The answer is derived from the most relevant chunk of the pre-processed document.

**Request Parameters:**

- user_name: (string) The name of the user.
- question: (string) The question the user wants to ask.

**Response:**

- answer: (string) The generated answer to the user's question.

Example request using `curl`:

```bash
   curl -X POST "http://127.0.0.1:8000/ask" \
  -H "accept: application/json" \
  -H "Content-Type: application/json" \
  -d '{
    "user_name": "Guille Griffa",
    "question": "What did Emma decide to do?"
  }'

```

Example response:

```json
{
   "answer":"Emma decides to share her magical day with the town, leaving a lasting impression on everyone.üßö‚ôÄÔ∏è"
   }
```

## Directory Structure

```plaintext
.
‚îú‚îÄ‚îÄ main.py               # FastAPI application entry point
‚îú‚îÄ‚îÄ doc_processing.py     # Functions for document processing and chunking
‚îú‚îÄ‚îÄ embeddings.py         # Functions for generating and storing embeddings
‚îú‚îÄ‚îÄ llm.py                # Functions for generating answers using Cohere's LLM
‚îú‚îÄ‚îÄ chromadb_client.py    # Initialize and manage ChromaDB collection     
‚îú‚îÄ‚îÄ requirements.txt      # List of project dependencies
‚îú‚îÄ‚îÄ document.docx         # Document to be processed
‚îú‚îÄ‚îÄ README.md             # Project documentation
```